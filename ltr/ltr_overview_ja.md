# NLP4L-LTR ランキング学習支援ツール

## コンセプト

ランキング学習支援ツールとは、ランキング学習に関する機能を検索サービス（Solr, Elasticsearch）で提供する上で必要となるいくつかの作業を支援するためのツールを提供するものです。

![NLP4L-LTRアーキテクチャー](images/ltr-concept.png)

ランキング学習をとりこんだ検索サービスを提供するためには、いくつかのフェーズにわけて作業を行う必要があります。各フェーズにおいて人の手で行わなければならない作業を効率化するための機能を提供することを目標としています。

1. 評価データ生成
2. Feature抽出
3. モデル生成
4. モデル配置


ランキング学習に関するモデル理論と実装は様々なものが存在しています。このツールでは、特定のモデル理論や実装には依存せず利用することが可能となっています。モデル実装のクラスは、ツール連携のための少しのインターフェイスを実装するだけで、ツールに取り込んで利用可能となります。

### 評価データ生成について

NLP4L-LTR が提供するランキング学習は、教師あり学習となります。そのため、あるクエリについてどの文書がどのくらい関連するかというデータが必要になってきます。このデータを用意するには、以下のような方法が考えられます。

- アノテーターがAnnotation付けを行う。
- クリックログを分析して作成する。

現在、NLP4L-LTR では1番目の方法をサポートしています。これは2番目の方法をサポートしないということではありません。クリックログを分析してその結果をデータベースに投入すれば、NLP4L-LTRの機能を使うことができます。アノテーターがAnnotation付けを行う方法は確実性が高いですがコストがかかり、時間経過と共にアノテーションデータが劣化する可能性があります。一方、クリックログを分析する方法では、ノイズが発生し、その性質もアプリケーション依存のところが多分にあります。

一般的に提案されているクリックログ分析のモデル（クリックモデル）には、以下のようなものがあります。

|名称|説明|
+:---+:---+
|Position Model|クリックが関連度と検査の両方に依存すると考える。それぞれの文書は検査される一定の確率を持っており、その確率はランクポジションのみに依存して減衰する。文書をクリックするということはその文書はユーザによって検査され、関連していると考えられる。|
|Cascade Model|ユーザは検索結果を順番に検査し、関連文書をクリックするとその検査を停止すると考える。ここで検査の確率は2つの要素「文書のランク」と「前にランクされたすべての文書の関連度」によって間接的に決定される。カスケードモデルでは検索一つに付きクリックは1回のみという強い前提をおいている。|
|Dependent Click Model|カスケードモデルではユーザは最初のクリックで文書の検査を停止すると考える。このため、残念ながら最大でも1クリックのクエリセッションというようにモデリング力を限定してしまっており、特に情報的な検索のように複数回のクリックを認める実世界のアプリケーションと大きなギャップがある。DCMは平均的なユーザが検索結果ページを返し、クリック後に検査を再開するモデルの確率へのポジション依存パラメータを含むことで、カスケードモデルを複数回クリックに適用する。|
|Bayesian Browsing Model|文書関連度のモデル化へのBayesianアプローチの効き目により、複数文書間におけるプリファレンス確率がよりよく定義され、文書関連度後の値をベースに計算できるようになる。これによりとりわけペアワイズのランキング学習アルゴリズムでの学習データとして利用できる。|
|Dynamic Bayesian Network Model|知覚的な関連度と実際の関連度をよりうまくモデル化するために提案された手法。このモデルでは、ユーザがURLを検査し、それが関連ありと認められるときに限りクリックが起きると仮定される。さらに、ユーザは検索結果上を線形的に横断し、文書の知覚的関連度に基づいてクリックするかどうかを決めると仮定される。ユーザはクリックしたURLに満足しなかった（これは実際の関連度に基づく）場合に検査するために次のURLを選ぶ。|

## アーキテクチャー

ランキング学習支援ツールのアーキテクチャ図を以下に示します。

![アーキテクチャー](images/ltr-architecture.png)

## 機能概要

以下に、ランキング学習支援ツールで提供されている機能の概要を示します。アーキテクチャー図と合わせて、ご覧ください。

###  Config
Configでは、ランキング学習支援ツールを動作させていく上での各種設定を行います。

- 評価方法選択（Pointwise, Pairwise, Listwise） （現在はPointwiseのみサポート）
- 検索サーバ（Solr/Elasticsearch）のURL指定 （現在はSolrのみサポート）
- Features取得方法、Features項目定義
- ドキュメントのid, titile, bodyフィールド名の指定
- 学習モデル生成のためのFactoryClass
- デプロイのためのFactoryClass

###  Query List
Query Listでは、評価対象のクエリーのリストを管理します。

- 評価対象のクエリーの一覧、ステータス
- クエリーファイルからのアップロード登録

###  Annotation
Annotationでは、検索サーバ(Solr/Elasticsearch)に対して、実際にクエリーを実行し、クエリー結果のドキュメント一覧に対して、ランキング評価(アノテーション付け)を行います。アノテーション付けは、関連度合の高いドキュメントに対して、星マークを付けることで行います。

- 検索サーバへのクエリ問い合わせ、結果ドキュメントの一覧表示
- Annotation付けと、Annotationデータ保存

###  Feature extraction

Solr/ElasticsearchのLTR-Featureモジュールと連動し、評価データ（クエリ、検索結果ドキュメント）に関するFeatureの値を取得します。取得したFeatureデータは、モデル生成時に利用されます。

- 評価データ（クエリ、検索結果ドキュメント）に関するFeatureの値の取得
- Solr/ElasticsearchのLTR-Featureモジュールとの連動
- Featureデータの保存

###  Train and Model creation
AnnotationデータとFeatureデータを利用して、トレーニングを行い、モデルデータを生成します。
トレーニングには、Configで設定した学習モデル生成Factoryクラスが利用されるため、様々なモデル実装を利用することができます

- AnnotationデータとFeatureデータを利用した機械学習とモデルの生成
- 生成したモデルのSolr/Elasticsearchへの配備(デプロイ)

生成・配備されたモデルは、Solr/ElasticsearchのLTR-ReRankモジュールと連動して、検索時のReRankに利用されます。


## NLP4Lのsolrプロジェクト

ランキング学習支援ツールは、Solr/Elasticsearch側のLTRモジュールと連動して動作します。（現時点では、Solrのみサポート）

Solr側の機能や設定に関しては、「[NLP4Lのsolrプロジェクト](https://github.com/NLP4L/solr)」を参照してください。



## 標準提供のモデル

NLP4Lでは、予め実装されたビルトインの学習モデル生成クラスが提供されています。

|モデル|アプローチ|説明|
|:--|:--|:--|
|PRank|Pointwise|PRank(Perceptron Ranking)アルゴリズムを利用したモデル|
|RankingSVM|疑似Pairwise|SVM(support vector machine)を用いたモデル。<br>Pointwiseデータから疑似的にpairwiseデータに変換して処理を行う。|

これらの標準提供モデル関しては、 [NLP4L-LTR User's Guide](ltr_users_guide_ja.md)を参照してください。

## ユーザ開発のモデル

NLP4Lでは、ビルトインのモデルだけでなく、ユーザがモデルを開発することも想定しています。

詳しくは、[NLP4L-LTR Programmer's Guide](ltr_programmers_guide_ja.md)を参照してください。
